{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import caffe\n",
    "from caffe.model_libs import *\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import stat\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Add extra layers on top of a \"base\" network (e.g. VGGNet or Inception).\n",
    "def AddExtraLayers(net, use_batchnorm=True, lr_mult=1):\n",
    "    use_relu = True\n",
    "\n",
    "    # Add additional convolutional layers.\n",
    "    # 19 x 19\n",
    "    from_layer = net.keys()[-1]\n",
    "\n",
    "    # TODO(weiliu89): Construct the name using the last layer to avoid duplication.\n",
    "    # 10 x 10\n",
    "    out_layer = \"conv6_1\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 256, 1, 0, 1,\n",
    "        lr_mult=lr_mult)\n",
    "\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv6_2\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 512, 3, 1, 2,\n",
    "        lr_mult=lr_mult)\n",
    "\n",
    "    # 5 x 5\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv7_1\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 128, 1, 0, 1,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv7_2\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 256, 3, 1, 2,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    # 3 x 3\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv8_1\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 128, 1, 0, 1,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv8_2\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 256, 3, 0, 1,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    # 1 x 1\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv9_1\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 128, 1, 0, 1,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    from_layer = out_layer\n",
    "    out_layer = \"conv9_2\"\n",
    "    ConvBNLayer(net, from_layer, out_layer, use_batchnorm, use_relu, 256, 3, 0, 1,\n",
    "      lr_mult=lr_mult)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "### Modify the following parameters accordingly ###\n",
    "# The directory which contains the caffe code.\n",
    "# We assume you are running the script at the CAFFE_ROOT.\n",
    "caffe_root = os.getcwd()\n",
    "\n",
    "# Set true if you want to start training right after generating all files.\n",
    "run_soon = True\n",
    "# Set true if you want to load from most recently saved snapshot.\n",
    "# Otherwise, we will load from the pretrain_model defined below.\n",
    "resume_training = True\n",
    "# If true, Remove old model files.\n",
    "remove_old_models = False\n",
    "\n",
    "# The database file for training data. Created by data/VOC0712/create_data.sh\n",
    "train_data = \"examples/VOC0712/VOC0712_trainval_lmdb\"\n",
    "# The database file for testing data. Created by data/VOC0712/create_data.sh\n",
    "test_data = \"examples/VOC0712/VOC0712_test_lmdb\"\n",
    "# Specify the batch sampler.\n",
    "resize_width = 300\n",
    "resize_height = 300\n",
    "resize = \"{}x{}\".format(resize_width, resize_height)\n",
    "batch_sampler = [\n",
    "        {\n",
    "                'sampler': {\n",
    "                        },\n",
    "                'max_trials': 1,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'min_jaccard_overlap': 0.1,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'min_jaccard_overlap': 0.3,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'min_jaccard_overlap': 0.5,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'min_jaccard_overlap': 0.7,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'min_jaccard_overlap': 0.9,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        {\n",
    "                'sampler': {\n",
    "                        'min_scale': 0.3,\n",
    "                        'max_scale': 1.0,\n",
    "                        'min_aspect_ratio': 0.5,\n",
    "                        'max_aspect_ratio': 2.0,\n",
    "                        },\n",
    "                'sample_constraint': {\n",
    "                        'max_jaccard_overlap': 1.0,\n",
    "                        },\n",
    "                'max_trials': 50,\n",
    "                'max_sample': 1,\n",
    "        },\n",
    "        ]\n",
    "train_transform_param = {\n",
    "        'mirror': True,\n",
    "        'mean_value': [104, 117, 123],\n",
    "        'resize_param': {\n",
    "                'prob': 1,\n",
    "                'resize_mode': P.Resize.WARP,\n",
    "                'height': resize_height,\n",
    "                'width': resize_width,\n",
    "                'interp_mode': [\n",
    "                        P.Resize.LINEAR,\n",
    "                        P.Resize.AREA,\n",
    "                        P.Resize.NEAREST,\n",
    "                        P.Resize.CUBIC,\n",
    "                        P.Resize.LANCZOS4,\n",
    "                        ],\n",
    "                },\n",
    "        'distort_param': {\n",
    "                'brightness_prob': 0.5,\n",
    "                'brightness_delta': 32,\n",
    "                'contrast_prob': 0.5,\n",
    "                'contrast_lower': 0.5,\n",
    "                'contrast_upper': 1.5,\n",
    "                'hue_prob': 0.5,\n",
    "                'hue_delta': 18,\n",
    "                'saturation_prob': 0.5,\n",
    "                'saturation_lower': 0.5,\n",
    "                'saturation_upper': 1.5,\n",
    "                'random_order_prob': 0.0,\n",
    "                },\n",
    "        'expand_param': {\n",
    "                'prob': 0.5,\n",
    "                'max_expand_ratio': 4.0,\n",
    "                },\n",
    "        'emit_constraint': {\n",
    "            'emit_type': caffe_pb2.EmitConstraint.CENTER,\n",
    "            }\n",
    "        }\n",
    "test_transform_param = {\n",
    "        'mean_value': [104, 117, 123],\n",
    "        'resize_param': {\n",
    "                'prob': 1,\n",
    "                'resize_mode': P.Resize.WARP,\n",
    "                'height': resize_height,\n",
    "                'width': resize_width,\n",
    "                'interp_mode': [P.Resize.LINEAR],\n",
    "                },\n",
    "        }\n",
    "\n",
    "# If true, use batch norm for all newly added layers.\n",
    "# Currently only the non batch norm version has been tested.\n",
    "use_batchnorm = False\n",
    "lr_mult = 1\n",
    "# Use different initial learning rate.\n",
    "if use_batchnorm:\n",
    "    base_lr = 0.0004\n",
    "else:\n",
    "    # A learning rate for batch_size = 1, num_gpus = 1.\n",
    "    base_lr = 0.00004\n",
    "\n",
    "# Modify the job name if you want.\n",
    "job_name = \"SSD_{}\".format(resize)\n",
    "# The name of the model. Modify it if you want.\n",
    "model_name = \"VGG_VOC0712_{}\".format(job_name)\n",
    "\n",
    "# Directory which stores the model .prototxt file.\n",
    "save_dir = \"models/VGGNet/VOC0712/{}\".format(job_name)\n",
    "# Directory which stores the snapshot of models.\n",
    "snapshot_dir = \"models/VGGNet/VOC0712/{}\".format(job_name)\n",
    "# Directory which stores the job script and log file.\n",
    "job_dir = \"jobs/VGGNet/VOC0712/{}\".format(job_name)\n",
    "# Directory which stores the detection results.\n",
    "output_result_dir = \"{}/data/VOCdevkit/results/VOC2007/{}/Main\".format(os.environ['HOME'], job_name)\n",
    "\n",
    "# model definition files.\n",
    "train_net_file = \"{}/train.prototxt\".format(save_dir)\n",
    "test_net_file = \"{}/test.prototxt\".format(save_dir)\n",
    "deploy_net_file = \"{}/deploy.prototxt\".format(save_dir)\n",
    "solver_file = \"{}/solver.prototxt\".format(save_dir)\n",
    "# snapshot prefix.\n",
    "snapshot_prefix = \"{}/{}\".format(snapshot_dir, model_name)\n",
    "# job script path.\n",
    "job_file = \"{}/{}.sh\".format(job_dir, model_name)\n",
    "\n",
    "# Stores the test image names and sizes. Created by data/VOC0712/create_list.sh\n",
    "name_size_file = \"data/VOC0712/test_name_size.txt\"\n",
    "# The pretrained model. We use the Fully convolutional reduced (atrous) VGGNet.\n",
    "pretrain_model = \"models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel\"\n",
    "# Stores LabelMapItem.\n",
    "label_map_file = \"data/VOC0712/labelmap_voc.prototxt\"\n",
    "\n",
    "# MultiBoxLoss parameters.\n",
    "num_classes = 21\n",
    "share_location = True\n",
    "background_label_id=0\n",
    "train_on_diff_gt = True\n",
    "normalization_mode = P.Loss.VALID\n",
    "code_type = P.PriorBox.CENTER_SIZE\n",
    "ignore_cross_boundary_bbox = False\n",
    "mining_type = P.MultiBoxLoss.MAX_NEGATIVE\n",
    "neg_pos_ratio = 3.\n",
    "loc_weight = (neg_pos_ratio + 1.) / 4.\n",
    "multibox_loss_param = {\n",
    "    'loc_loss_type': P.MultiBoxLoss.SMOOTH_L1,\n",
    "    'conf_loss_type': P.MultiBoxLoss.SOFTMAX,\n",
    "    'loc_weight': loc_weight,\n",
    "    'num_classes': num_classes,\n",
    "    'share_location': share_location,\n",
    "    'match_type': P.MultiBoxLoss.PER_PREDICTION,\n",
    "    'overlap_threshold': 0.5,\n",
    "    'use_prior_for_matching': True,\n",
    "    'background_label_id': background_label_id,\n",
    "    'use_difficult_gt': train_on_diff_gt,\n",
    "    'mining_type': mining_type,\n",
    "    'neg_pos_ratio': neg_pos_ratio,\n",
    "    'neg_overlap': 0.5,\n",
    "    'code_type': code_type,\n",
    "    'ignore_cross_boundary_bbox': ignore_cross_boundary_bbox,\n",
    "    }\n",
    "loss_param = {\n",
    "    'normalization': normalization_mode,\n",
    "    }\n",
    "\n",
    "# parameters for generating priors.\n",
    "# minimum dimension of input image\n",
    "min_dim = 300\n",
    "# conv4_3 ==> 38 x 38\n",
    "# fc7 ==> 19 x 19\n",
    "# conv6_2 ==> 10 x 10\n",
    "# conv7_2 ==> 5 x 5\n",
    "# conv8_2 ==> 3 x 3\n",
    "# conv9_2 ==> 1 x 1\n",
    "mbox_source_layers = ['conv4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'conv9_2']\n",
    "# in percent %\n",
    "min_ratio = 20\n",
    "max_ratio = 90\n",
    "step = int(math.floor((max_ratio - min_ratio) / (len(mbox_source_layers) - 2)))\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in xrange(min_ratio, max_ratio + 1, step):\n",
    "  min_sizes.append(min_dim * ratio / 100.)\n",
    "  max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 10 / 100.] + min_sizes\n",
    "max_sizes = [min_dim * 20 / 100.] + max_sizes\n",
    "steps = [8, 16, 32, 64, 100, 300]\n",
    "aspect_ratios = [[2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
    "# L2 normalize conv4_3.\n",
    "normalizations = [20, -1, -1, -1, -1, -1]\n",
    "# variance used to encode/decode prior bboxes.\n",
    "if code_type == P.PriorBox.CENTER_SIZE:\n",
    "  prior_variance = [0.1, 0.1, 0.2, 0.2]\n",
    "else:\n",
    "  prior_variance = [0.1]\n",
    "flip = True\n",
    "clip = False\n",
    "\n",
    "# Solver parameters.\n",
    "# Defining which GPUs to use.\n",
    "gpus = \"0,1,2,3\"\n",
    "gpulist = gpus.split(\",\")\n",
    "num_gpus = len(gpulist)\n",
    "\n",
    "# Divide the mini-batch to different GPUs.\n",
    "batch_size = 32\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "solver_mode = P.Solver.CPU\n",
    "device_id = 0\n",
    "batch_size_per_device = batch_size\n",
    "if num_gpus > 0:\n",
    "  batch_size_per_device = int(math.ceil(float(batch_size) / num_gpus))\n",
    "  iter_size = int(math.ceil(float(accum_batch_size) / (batch_size_per_device * num_gpus)))\n",
    "  solver_mode = P.Solver.GPU\n",
    "  device_id = int(gpulist[0])\n",
    "\n",
    "if normalization_mode == P.Loss.NONE:\n",
    "  base_lr /= batch_size_per_device\n",
    "elif normalization_mode == P.Loss.VALID:\n",
    "  base_lr *= 25. / loc_weight\n",
    "elif normalization_mode == P.Loss.FULL:\n",
    "  # Roughly there are 2000 prior bboxes per image.\n",
    "  # TODO(weiliu89): Estimate the exact # of priors.\n",
    "  base_lr *= 2000.\n",
    "\n",
    "# Evaluate on whole test set.\n",
    "num_test_image = 4952\n",
    "test_batch_size = 8\n",
    "# Ideally test_batch_size should be divisible by num_test_image,\n",
    "# otherwise mAP will be slightly off the true value.\n",
    "test_iter = int(math.ceil(float(num_test_image) / test_batch_size))\n",
    "\n",
    "solver_param = {\n",
    "    # Train parameters\n",
    "    'base_lr': base_lr,\n",
    "    'weight_decay': 0.0005,\n",
    "    'lr_policy': \"multistep\",\n",
    "    'stepvalue': [80000, 100000, 120000],\n",
    "    'gamma': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'iter_size': iter_size,\n",
    "    'max_iter': 120000,\n",
    "    'snapshot': 80000,\n",
    "    'display': 10,\n",
    "    'average_loss': 10,\n",
    "    'type': \"SGD\",\n",
    "    'solver_mode': solver_mode,\n",
    "    'device_id': device_id,\n",
    "    'debug_info': False,\n",
    "    'snapshot_after_train': True,\n",
    "    # Test parameters\n",
    "    'test_iter': [test_iter],\n",
    "    'test_interval': 10000,\n",
    "    'eval_type': \"detection\",\n",
    "    'ap_version': \"11point\",\n",
    "    'test_initialization': False,\n",
    "    }\n",
    "\n",
    "# parameters for generating detection output.\n",
    "det_out_param = {\n",
    "    'num_classes': num_classes,\n",
    "    'share_location': share_location,\n",
    "    'background_label_id': background_label_id,\n",
    "    'nms_param': {'nms_threshold': 0.45, 'top_k': 400},\n",
    "    'save_output_param': {\n",
    "        'output_directory': output_result_dir,\n",
    "        'output_name_prefix': \"comp4_det_test_\",\n",
    "        'output_format': \"VOC\",\n",
    "        'label_map_file': label_map_file,\n",
    "        'name_size_file': name_size_file,\n",
    "        'num_test_image': num_test_image,\n",
    "        },\n",
    "    'keep_top_k': 200,\n",
    "    'confidence_threshold': 0.01,\n",
    "    'code_type': code_type,\n",
    "    }\n",
    "\n",
    "# parameters for evaluating detection results.\n",
    "det_eval_param = {\n",
    "    'num_classes': num_classes,\n",
    "    'background_label_id': background_label_id,\n",
    "    'overlap_threshold': 0.5,\n",
    "    'evaluate_difficult_gt': False,\n",
    "    'name_size_file': name_size_file,\n",
    "    }\n",
    "\n",
    "### Hopefully you don't need to change the following ###\n",
    "# Check file.\n",
    "check_if_exist(train_data)\n",
    "check_if_exist(test_data)\n",
    "check_if_exist(label_map_file)\n",
    "check_if_exist(pretrain_model)\n",
    "make_if_not_exist(save_dir)\n",
    "make_if_not_exist(job_dir)\n",
    "make_if_not_exist(snapshot_dir)\n",
    "\n",
    "# Create train net.\n",
    "net = caffe.NetSpec()\n",
    "net.data, net.label = CreateAnnotatedDataLayer(train_data, batch_size=batch_size_per_device,\n",
    "        train=True, output_label=True, label_map_file=label_map_file,\n",
    "        transform_param=train_transform_param, batch_sampler=batch_sampler)\n",
    "\n",
    "VGGNetBody(net, from_layer='data', fully_conv=True, reduced=True, dilated=True,\n",
    "    dropout=False)\n",
    "\n",
    "AddExtraLayers(net, use_batchnorm, lr_mult=lr_mult)\n",
    "\n",
    "mbox_layers = CreateMultiBoxHead(net, data_layer='data', from_layers=mbox_source_layers,\n",
    "        use_batchnorm=use_batchnorm, min_sizes=min_sizes, max_sizes=max_sizes,\n",
    "        aspect_ratios=aspect_ratios, steps=steps, normalizations=normalizations,\n",
    "        num_classes=num_classes, share_location=share_location, flip=flip, clip=clip,\n",
    "        prior_variance=prior_variance, kernel_size=3, pad=1, lr_mult=lr_mult)\n",
    "\n",
    "# Create the MultiBoxLossLayer.\n",
    "name = \"mbox_loss\"\n",
    "mbox_layers.append(net.label)\n",
    "net[name] = L.MultiBoxLoss(*mbox_layers, multibox_loss_param=multibox_loss_param,\n",
    "        loss_param=loss_param, include=dict(phase=caffe_pb2.Phase.Value('TRAIN')),\n",
    "        propagate_down=[True, True, False, False])\n",
    "\n",
    "with open(train_net_file, 'w') as f:\n",
    "    print('name: \"{}_train\"'.format(model_name), file=f)\n",
    "    print(net.to_proto(), file=f)\n",
    "shutil.copy(train_net_file, job_dir)\n",
    "\n",
    "# Create test net.\n",
    "net = caffe.NetSpec()\n",
    "net.data, net.label = CreateAnnotatedDataLayer(test_data, batch_size=test_batch_size,\n",
    "        train=False, output_label=True, label_map_file=label_map_file,\n",
    "        transform_param=test_transform_param)\n",
    "\n",
    "VGGNetBody(net, from_layer='data', fully_conv=True, reduced=True, dilated=True,\n",
    "    dropout=False)\n",
    "\n",
    "AddExtraLayers(net, use_batchnorm, lr_mult=lr_mult)\n",
    "\n",
    "mbox_layers = CreateMultiBoxHead(net, data_layer='data', from_layers=mbox_source_layers,\n",
    "        use_batchnorm=use_batchnorm, min_sizes=min_sizes, max_sizes=max_sizes,\n",
    "        aspect_ratios=aspect_ratios, steps=steps, normalizations=normalizations,\n",
    "        num_classes=num_classes, share_location=share_location, flip=flip, clip=clip,\n",
    "        prior_variance=prior_variance, kernel_size=3, pad=1, lr_mult=lr_mult)\n",
    "\n",
    "conf_name = \"mbox_conf\"\n",
    "if multibox_loss_param[\"conf_loss_type\"] == P.MultiBoxLoss.SOFTMAX:\n",
    "  reshape_name = \"{}_reshape\".format(conf_name)\n",
    "  net[reshape_name] = L.Reshape(net[conf_name], shape=dict(dim=[0, -1, num_classes]))\n",
    "  softmax_name = \"{}_softmax\".format(conf_name)\n",
    "  net[softmax_name] = L.Softmax(net[reshape_name], axis=2)\n",
    "  flatten_name = \"{}_flatten\".format(conf_name)\n",
    "  net[flatten_name] = L.Flatten(net[softmax_name], axis=1)\n",
    "  mbox_layers[1] = net[flatten_name]\n",
    "elif multibox_loss_param[\"conf_loss_type\"] == P.MultiBoxLoss.LOGISTIC:\n",
    "  sigmoid_name = \"{}_sigmoid\".format(conf_name)\n",
    "  net[sigmoid_name] = L.Sigmoid(net[conf_name])\n",
    "  mbox_layers[1] = net[sigmoid_name]\n",
    "\n",
    "net.detection_out = L.DetectionOutput(*mbox_layers,\n",
    "    detection_output_param=det_out_param,\n",
    "    include=dict(phase=caffe_pb2.Phase.Value('TEST')))\n",
    "net.detection_eval = L.DetectionEvaluate(net.detection_out, net.label,\n",
    "    detection_evaluate_param=det_eval_param,\n",
    "    include=dict(phase=caffe_pb2.Phase.Value('TEST')))\n",
    "\n",
    "with open(test_net_file, 'w') as f:\n",
    "    print('name: \"{}_test\"'.format(model_name), file=f)\n",
    "    print(net.to_proto(), file=f)\n",
    "shutil.copy(test_net_file, job_dir)\n",
    "\n",
    "# Create deploy net.\n",
    "# Remove the first and last layer from test net.\n",
    "deploy_net = net\n",
    "with open(deploy_net_file, 'w') as f:\n",
    "    net_param = deploy_net.to_proto()\n",
    "    # Remove the first (AnnotatedData) and last (DetectionEvaluate) layer from test net.\n",
    "    del net_param.layer[0]\n",
    "    del net_param.layer[-1]\n",
    "    net_param.name = '{}_deploy'.format(model_name)\n",
    "    net_param.input.extend(['data'])\n",
    "    net_param.input_shape.extend([\n",
    "        caffe_pb2.BlobShape(dim=[1, 3, resize_height, resize_width])])\n",
    "    print(net_param, file=f)\n",
    "shutil.copy(deploy_net_file, job_dir)\n",
    "\n",
    "# Create solver.\n",
    "solver = caffe_pb2.SolverParameter(\n",
    "        train_net=train_net_file,\n",
    "        test_net=[test_net_file],\n",
    "        snapshot_prefix=snapshot_prefix,\n",
    "        **solver_param)\n",
    "\n",
    "with open(solver_file, 'w') as f:\n",
    "    print(solver, file=f)\n",
    "shutil.copy(solver_file, job_dir)\n",
    "\n",
    "max_iter = 0\n",
    "# Find most recent snapshot.\n",
    "for file in os.listdir(snapshot_dir):\n",
    "  if file.endswith(\".solverstate\"):\n",
    "    basename = os.path.splitext(file)[0]\n",
    "    iter = int(basename.split(\"{}_iter_\".format(model_name))[1])\n",
    "    if iter > max_iter:\n",
    "      max_iter = iter\n",
    "\n",
    "train_src_param = '--weights=\"{}\" \\\\\\n'.format(pretrain_model)\n",
    "if resume_training:\n",
    "  if max_iter > 0:\n",
    "    train_src_param = '--snapshot=\"{}_iter_{}.solverstate\" \\\\\\n'.format(snapshot_prefix, max_iter)\n",
    "\n",
    "if remove_old_models:\n",
    "  # Remove any snapshots smaller than max_iter.\n",
    "  for file in os.listdir(snapshot_dir):\n",
    "    if file.endswith(\".solverstate\"):\n",
    "      basename = os.path.splitext(file)[0]\n",
    "      iter = int(basename.split(\"{}_iter_\".format(model_name))[1])\n",
    "      if max_iter > iter:\n",
    "        os.remove(\"{}/{}\".format(snapshot_dir, file))\n",
    "    if file.endswith(\".caffemodel\"):\n",
    "      basename = os.path.splitext(file)[0]\n",
    "      iter = int(basename.split(\"{}_iter_\".format(model_name))[1])\n",
    "      if max_iter > iter:\n",
    "        os.remove(\"{}/{}\".format(snapshot_dir, file))\n",
    "\n",
    "# Create job file.\n",
    "with open(job_file, 'w') as f:\n",
    "  f.write('cd {}\\n'.format(caffe_root))\n",
    "  f.write('./build/tools/caffe train \\\\\\n')\n",
    "  f.write('--solver=\"{}\" \\\\\\n'.format(solver_file))\n",
    "  f.write(train_src_param)\n",
    "  if solver_param['solver_mode'] == P.Solver.GPU:\n",
    "    f.write('--gpu {} 2>&1 | tee {}/{}.log\\n'.format(gpus, job_dir, model_name))\n",
    "  else:\n",
    "    f.write('2>&1 | tee {}/{}.log\\n'.format(job_dir, model_name))\n",
    "\n",
    "# Copy the python script to job_dir.\n",
    "py_file = os.path.abspath(__file__)\n",
    "shutil.copy(py_file, job_dir)\n",
    "\n",
    "# Run the job.\n",
    "os.chmod(job_file, stat.S_IRWXU)\n",
    "if run_soon:\n",
    "  subprocess.call(job_file, shell=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
